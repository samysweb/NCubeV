{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will train with a modified reward scheme..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n"
     ]
    }
   ],
   "source": [
    "import zeppelin_gym.env6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fde315695f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/envs/nnv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('zeppelin-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.FUEL_RESTRAINT = False\n",
    "env.unwrapped.OBSTACLE_REWARD = -1000.\n",
    "env.unwrapped.NO_FUEL_REWARD = 0.1\n",
    "# done reward = (FUEL_RESTRAINT) ? r+fuel*r : 2*r\n",
    "env.unwrapped.DONE_REWARD = 0.5\n",
    "env.unwrapped.INCLUDE_UNWINNABLE = False\n",
    "env.unwrapped.EMERGENCY_REWARD = -1e-4\n",
    "env.unwrapped.WORST_CASE_TURBULENCE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "architecture = [dict(pi=[8,8], vf=[8,8])]\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,policy_kwargs={\"activation_fn\":nn.ReLU,\"net_arch\":architecture})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-713.53 +/- 1455.04\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.5     |\n",
      "|    ep_rew_mean     | -543     |\n",
      "| time/              |          |\n",
      "|    fps             | 2752     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.7        |\n",
      "|    ep_rew_mean          | -577        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1929        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053349447 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.08e+04    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 5.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.3       |\n",
      "|    ep_rew_mean          | -636       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1775       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02603676 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.25      |\n",
      "|    explained_variance   | -0.0969    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.35e+04   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.0115     |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 6.77e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.9        |\n",
      "|    ep_rew_mean          | -619        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1700        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027999343 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.5        |\n",
      "|    ep_rew_mean          | -579        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1655        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021704167 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.65e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00557     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.16e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.1       |\n",
      "|    ep_rew_mean          | -597       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1610       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02290567 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.26      |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.99e+04   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.0171     |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 3.94e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.8        |\n",
      "|    ep_rew_mean          | -574        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021640262 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+04    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.71e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.3        |\n",
      "|    ep_rew_mean          | -579        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019220274 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+04    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.6e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.4       |\n",
      "|    ep_rew_mean          | -557       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1591       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03025724 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.25      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.51e+04   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.00692    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 3.46e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.5        |\n",
      "|    ep_rew_mean          | -582        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017088037 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+04    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 3.03e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | -514        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021017494 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+04    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 3.08e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.2       |\n",
      "|    ep_rew_mean          | -592       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1588       |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02807568 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.24      |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.39e+04   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.0127     |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 2.67e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.2        |\n",
      "|    ep_rew_mean          | -524        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025015935 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+04    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.00841     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 3.05e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.1        |\n",
      "|    ep_rew_mean          | -477        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024468143 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.24e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.0145      |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 2.08e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.3        |\n",
      "|    ep_rew_mean          | -489        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021793172 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.71e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 1.67e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | -505        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018340716 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.45e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 2.18e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.9        |\n",
      "|    ep_rew_mean          | -482        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040159345 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.15e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 13.2      |\n",
      "|    ep_rew_mean          | -488      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1583      |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0271676 |\n",
      "|    clip_fraction        | 0.198     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.19     |\n",
      "|    explained_variance   | 0.465     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.94e+03  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | 0.0103    |\n",
      "|    std                  | 0.978     |\n",
      "|    value_loss           | 1.49e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.2        |\n",
      "|    ep_rew_mean          | -485        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022169866 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+04    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00632     |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.5        |\n",
      "|    ep_rew_mean          | -493        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017391423 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.76e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.00875     |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.6        |\n",
      "|    ep_rew_mean          | -504        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014999852 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00554     |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 14.9      |\n",
      "|    ep_rew_mean          | -489      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1583      |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0189971 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.16     |\n",
      "|    explained_variance   | 0.453     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.64e+03  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 0.00674   |\n",
      "|    std                  | 0.966     |\n",
      "|    value_loss           | 1.59e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.6        |\n",
      "|    ep_rew_mean          | -495        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018697504 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5e+03       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00995     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.5        |\n",
      "|    ep_rew_mean          | -496        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019371655 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.17e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00659     |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.1       |\n",
      "|    ep_rew_mean          | -494       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1584       |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03296465 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.1       |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1e+04      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    std                  | 0.949      |\n",
      "|    value_loss           | 1.42e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.9        |\n",
      "|    ep_rew_mean          | -447        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024982095 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.45e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | -475        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015807347 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.37e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00932     |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 1.13e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.4        |\n",
      "|    ep_rew_mean          | -458        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037231006 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | -421        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024813723 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.07e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00384     |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.4        |\n",
      "|    ep_rew_mean          | -443        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034076102 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.05e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 9.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.7        |\n",
      "|    ep_rew_mean          | -474        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027761709 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 8.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | -445        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018798707 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.31e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00979     |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 9.14e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | -412        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029076684 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00961     |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.5       |\n",
      "|    ep_rew_mean          | -482       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1591       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01911435 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.02      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.55e+03   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.0152     |\n",
      "|    std                  | 0.928      |\n",
      "|    value_loss           | 1.03e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.4        |\n",
      "|    ep_rew_mean          | -480        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020682346 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.42e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00734     |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 1.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.9        |\n",
      "|    ep_rew_mean          | -446        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1592        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018355504 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.49e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0075      |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.6       |\n",
      "|    ep_rew_mean          | -417       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1593       |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06896115 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.98      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.67e+03   |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    std                  | 0.916      |\n",
      "|    value_loss           | 9.54e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17          |\n",
      "|    ep_rew_mean          | -436        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026868911 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+03     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.911       |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 15.5       |\n",
      "|    ep_rew_mean          | -421       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1593       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03322591 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.94      |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.57e+03   |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | 0.0135     |\n",
      "|    std                  | 0.904      |\n",
      "|    value_loss           | 1.06e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | -414        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018721268 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+03    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 9.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.4       |\n",
      "|    ep_rew_mean          | -395       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1593       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01819097 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.9       |\n",
      "|    explained_variance   | 0.595      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.06e+03   |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.00863    |\n",
      "|    std                  | 0.895      |\n",
      "|    value_loss           | 7.27e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 24.3       |\n",
      "|    ep_rew_mean          | -398       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1595       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02321439 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.88      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.19e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | 0.0205     |\n",
      "|    std                  | 0.89       |\n",
      "|    value_loss           | 7.73e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.3       |\n",
      "|    ep_rew_mean          | -416       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1596       |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03458461 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.86      |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.33e+03   |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.0124     |\n",
      "|    std                  | 0.885      |\n",
      "|    value_loss           | 5.76e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | -411        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1596        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021083934 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.78e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00591     |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 9.8e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.2       |\n",
      "|    ep_rew_mean          | -402       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1595       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15857515 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.83      |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.36e+03   |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.0357     |\n",
      "|    std                  | 0.878      |\n",
      "|    value_loss           | 8.21e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 28.3      |\n",
      "|    ep_rew_mean          | -409      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1594      |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0336665 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.82     |\n",
      "|    explained_variance   | 0.558     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.53e+03  |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 0.0104    |\n",
      "|    std                  | 0.879     |\n",
      "|    value_loss           | 7.55e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.1        |\n",
      "|    ep_rew_mean          | -415        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030778177 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00995     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 5.76e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.5       |\n",
      "|    ep_rew_mean          | -375       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1593       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11065402 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.8       |\n",
      "|    explained_variance   | 0.596      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02e+03   |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.029      |\n",
      "|    std                  | 0.878      |\n",
      "|    value_loss           | 3.7e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -431        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1592        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058627903 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 984         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 5.48e+03    |\n",
      "-----------------------------------------\n",
      "--- 63.57614278793335 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-541.25 +/- 1019.23\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -354     |\n",
      "| time/              |          |\n",
      "|    fps             | 2853     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 34.6       |\n",
      "|    ep_rew_mean          | -421       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2015       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11637619 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.77      |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.61e+03   |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.0241     |\n",
      "|    std                  | 0.868      |\n",
      "|    value_loss           | 3.54e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | -458        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1828        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031400904 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00908     |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 8.52e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 44        |\n",
      "|    ep_rew_mean          | -417      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1722      |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0217594 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.76     |\n",
      "|    explained_variance   | 0.771     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.42e+03  |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | 0.00803   |\n",
      "|    std                  | 0.869     |\n",
      "|    value_loss           | 5.06e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.2        |\n",
      "|    ep_rew_mean          | -481        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1682        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018113725 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 438         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -528        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1661        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014335839 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03e+03    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.5        |\n",
      "|    ep_rew_mean          | -464        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1645        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012765886 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73e+03    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 1.81e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47.9        |\n",
      "|    ep_rew_mean          | -416        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1627        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027153803 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.0137      |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 8.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.5        |\n",
      "|    ep_rew_mean          | -394        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1611        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025386073 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.00777     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 7.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.9        |\n",
      "|    ep_rew_mean          | -378        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1603        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061018042 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 469         |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.0327      |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 61.5       |\n",
      "|    ep_rew_mean          | -364       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1595       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06268133 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.52e+03   |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | 0.00254    |\n",
      "|    std                  | 0.858      |\n",
      "|    value_loss           | 8.79e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.5        |\n",
      "|    ep_rew_mean          | -365        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062253278 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 266         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 3.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.2        |\n",
      "|    ep_rew_mean          | -391        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016952615 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 606         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.3        |\n",
      "|    ep_rew_mean          | -373        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024951782 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00936     |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 5.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -377        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044285055 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -366        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010088292 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.71e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41          |\n",
      "|    ep_rew_mean          | -348        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012474606 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.45e+03    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 7.82e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.3       |\n",
      "|    ep_rew_mean          | -394       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1592       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05479938 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.69      |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 950        |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | 0.0189     |\n",
      "|    std                  | 0.859      |\n",
      "|    value_loss           | 3.53e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 39.1        |\n",
      "|    ep_rew_mean          | -415        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017996384 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.99e+03    |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.00934     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 9.93e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50.5       |\n",
      "|    ep_rew_mean          | -377       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1596       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08163744 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.71      |\n",
      "|    explained_variance   | 0.559      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.38e+03   |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.0209     |\n",
      "|    std                  | 0.865      |\n",
      "|    value_loss           | 6.21e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.5        |\n",
      "|    ep_rew_mean          | -394        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099325225 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.13e+03    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.00973     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 4.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.6        |\n",
      "|    ep_rew_mean          | -413        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024086803 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.0218      |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 8.15e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 43.7       |\n",
      "|    ep_rew_mean          | -437       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1600       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01613547 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.481      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.21e+03   |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.00531    |\n",
      "|    std                  | 0.862      |\n",
      "|    value_loss           | 1.16e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33         |\n",
      "|    ep_rew_mean          | -338       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1601       |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01739226 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.69      |\n",
      "|    explained_variance   | 0.548      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.84e+03   |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.000526  |\n",
      "|    std                  | 0.861      |\n",
      "|    value_loss           | 4.97e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42          |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045309596 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 42.6      |\n",
      "|    ep_rew_mean          | -347      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1602      |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1406467 |\n",
      "|    clip_fraction        | 0.501     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.68     |\n",
      "|    explained_variance   | 0.489     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.5e+03   |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | 0.0389    |\n",
      "|    std                  | 0.865     |\n",
      "|    value_loss           | 3.34e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -407        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018133191 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -422        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028051227 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.98e+03    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00876     |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010605076 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.43e+03    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | -387        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1601        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031699575 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.93e+03    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 6.33e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 41.3       |\n",
      "|    ep_rew_mean          | -453       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1601       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07982176 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.43e+03   |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.0221     |\n",
      "|    std                  | 0.865      |\n",
      "|    value_loss           | 6.85e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.4        |\n",
      "|    ep_rew_mean          | -413        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1601        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017418426 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.63e+03    |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.00332     |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 39.4        |\n",
      "|    ep_rew_mean          | -397        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041644543 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.28e+03    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.0501      |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 2.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.5        |\n",
      "|    ep_rew_mean          | -427        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016627122 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.48e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -1.24e-06   |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 1.01e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.5        |\n",
      "|    ep_rew_mean          | -434        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1601        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049012233 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.1e+03     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.000961   |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 9.74e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.5       |\n",
      "|    ep_rew_mean          | -450       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1602       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03270019 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 330        |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | 0.0149     |\n",
      "|    std                  | 0.885      |\n",
      "|    value_loss           | 8.65e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44          |\n",
      "|    ep_rew_mean          | -462        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009489883 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+03    |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 8.16e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.2        |\n",
      "|    ep_rew_mean          | -489        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050032504 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.39e+03    |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | 0.00444     |\n",
      "|    std                  | 0.883       |\n",
      "|    value_loss           | 9.29e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27.2       |\n",
      "|    ep_rew_mean          | -432       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1601       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02261566 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.81e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00354   |\n",
      "|    std                  | 0.879      |\n",
      "|    value_loss           | 1.2e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | -449       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1601       |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03931665 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.74      |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.16e+03   |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.0107     |\n",
      "|    std                  | 0.874      |\n",
      "|    value_loss           | 1.12e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | -442        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014031165 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68e+04    |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.00504     |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.6        |\n",
      "|    ep_rew_mean          | -415        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056270003 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.0046      |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 6.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -446        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1601        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019559223 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.57e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | 0.00418     |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.5        |\n",
      "|    ep_rew_mean          | -499        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1600        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013557961 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.000632   |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 1.82e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.1        |\n",
      "|    ep_rew_mean          | -441        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1600        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021497898 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.93e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00856     |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 5.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -350        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1600        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017284961 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+04    |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | -479        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1599        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032806452 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.0306      |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 8.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | -473        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019521493 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.05e+03    |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | 0.00384     |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 1.65e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -414       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1594       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08327633 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.42e+03   |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | 0.007      |\n",
      "|    std                  | 0.866      |\n",
      "|    value_loss           | 9.54e+03   |\n",
      "----------------------------------------\n",
      "--- 63.48321866989136 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_reward, std_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_reward:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:86\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     84\u001b[0m episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((env\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m---> 86\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n\u001b[1;32m     88\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:579\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    561\u001b[0m     observation: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    565\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    335\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 338\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Convert to numpy\u001b[39;00m\n\u001b[1;32m    340\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:630\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: th\u001b[38;5;241m.\u001b[39mTensor, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:659\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    657\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[1;32m    658\u001b[0m latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(features)\n\u001b[0;32m--> 659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:607\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    604\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py:153\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/torch/distributions/normal.py:54\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNormal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/torch/distributions/distribution.py:53\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip checking lazily-constructed args\u001b[39;00m\n\u001b[1;32m     52\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[0;32m---> 53\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nnv/lib/python3.8/site-packages/torch/distributions/constraints.py:320\u001b[0m, in \u001b[0;36m_GreaterThan.check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_bound\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-200000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-300000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-400000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=500000,log_interval=10000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-1000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=500000,log_interval=1000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-1500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=1000000,log_interval=1000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-2500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=1000000,log_interval=1000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-3500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=1000000,log_interval=1000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-4500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=1000000,log_interval=1000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-v2.2-5500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "env.seed(43)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above ran while tab was closed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-v2-5500000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-v2-400000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=1000000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-6500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1300000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1400000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "env.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-avoidance-windsystem-small2-1500000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1600000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1700000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model=model.learn(total_timesteps=100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"zeppelin-avoidance-windsystem-small2-1800000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "env.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-avoidance-windsystem-small2-1400000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, reward_threshold=1.0, n_eval_episodes=1000000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, reward_threshold=1.0, n_eval_episodes=4000000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-avoidance-windsystem-small2-1400000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"hi\")\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    env.unwrapped.state=[-5,110,50,22]\n",
    "    total_reward=0\n",
    "    for t in range(1000):\n",
    "        action, _states = model.predict(observation)\n",
    "        #x1_norm = observation[0]/np.sqrt(observation[0]**2+observation[1]**2)\n",
    "        #x2_norm = observation[1]/np.sqrt(observation[0]**2+observation[1]**2)\n",
    "        #f = 1.0 if (x2_norm) < 0 else -1.0\n",
    "        #action = [f, f*(0-x1_norm)]\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(observation)\n",
    "        total_reward=0.99*total_reward+reward\n",
    "        env.render()\n",
    "        time.sleep(0.5)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            print(\"Reward: \", total_reward)\n",
    "            time.sleep(5.0)\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "env.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"zeppelin-avoidance-windsystem-small2-1400000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.WORST_CASE_TURBULENCE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.WORST_CASE_TURBULENCE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "env.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.WORST_CASE_TURBULENCE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.WORST_CASE_TURBULENCE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"zeppelin-v2.2-5500000\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 210.01126 -402.88406   23.98714   12.03044 -238.70241  154.28203]\n",
      "Episode finished after 167 timesteps (0 emergencies)\n",
      "Reward:  0.09656344660313382\n",
      "[-152.94023 -414.57919   35.61258   28.41249  392.57323  189.89173]\n",
      "Episode finished after 35 timesteps (0 emergencies)\n",
      "Reward:  -72.91031805941816\n",
      "[-13.61298  24.41259  24.59131  16.11797  96.26249  86.78461]\n",
      "Episode finished after 3 timesteps (0 emergencies)\n",
      "Reward:  -1000.0000202798225\n",
      "[ -30.10343   75.10588   78.36185   26.70478    8.14663 -104.22094]\n",
      "Episode finished after 13 timesteps (0 emergencies)\n",
      "Reward:  -1127.7029244266116\n",
      "[  92.6957  -401.23244   15.57599   16.41171 -108.32749  347.62149]\n",
      "Episode finished after 92 timesteps (0 emergencies)\n",
      "Reward:  0.0980576689723\n",
      "[  49.20122   31.99545   55.8393    18.97518 -133.39123 -105.46829]\n",
      "Episode finished after 2 timesteps (0 emergencies)\n",
      "Reward:  -1056.3491473908125\n",
      "[  91.03862 -406.65768   24.31299   18.37157 -262.17891 -262.32858]\n",
      "Episode finished after 47 timesteps (0 emergencies)\n",
      "Reward:  -2.5863583361459095\n",
      "[  54.22877 -408.54957   18.42542   24.93989  -12.61399  256.0241 ]\n",
      "Episode finished after 39 timesteps (0 emergencies)\n",
      "Reward:  0.09902712467333076\n",
      "[-198.61366 -401.47499   31.15234   24.90943  392.1119  -131.73492]\n",
      "Episode finished after 35 timesteps (0 emergencies)\n",
      "Reward:  -92.41405270327941\n",
      "[ -15.49724   30.20066   33.50232   22.93508 -276.60194 -179.59745]\n",
      "Episode finished after 7 timesteps (0 emergencies)\n",
      "Reward:  -1009.0626504346092\n"
     ]
    }
   ],
   "source": [
    "env.unwrapped.INCLUDE_UNWINNABLE = False\n",
    "#env.init_polytopes(0.0,retrain_polytopes_certain)\n",
    "for i_episode in range(10):\n",
    "    observation = env.reset()\n",
    "    observation = env.unwrapped.state\n",
    "    total_reward=0\n",
    "    emergencies=0\n",
    "    for t in range(1000):\n",
    "        #print(observation)\n",
    "        x1,x2,c,w,g1,g2 = observation\n",
    "        #action = [0.,0.,0.0]\n",
    "        \n",
    "        #action=[0.,0.,1.]\n",
    "        action, _states = model.predict(observation,deterministic=True)\n",
    "        if action[2] > env.unwrapped.EMERGENCY_THRESHOLD:\n",
    "            emergencies+=1\n",
    "        #print([action[1]*action[0],action[1]*np.sqrt(1-action[0]**2)])\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #assert reward >= 0, f\"reward: {reward}\"\n",
    "        total_reward=0.99*total_reward+reward\n",
    "        env.render()\n",
    "        time.sleep(0.01)\n",
    "        if done:\n",
    "            print(observation)\n",
    "            print(\"Episode finished after {} timesteps ({} emergencies)\".format(t+1,emergencies))\n",
    "            print(\"Reward: \", total_reward)\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
