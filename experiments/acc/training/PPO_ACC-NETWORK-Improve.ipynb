{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxableActionPolicy(torch.nn.Module):\n",
    "    def __init__(self, extractor, action_net, value_net):\n",
    "        super(OnnxableActionPolicy, self).__init__()\n",
    "        self.extractor = extractor\n",
    "        self.action_net = action_net\n",
    "        self.value_net = value_net\n",
    "        normalize_linear1 = torch.nn.Linear(1, 4)\n",
    "        # 100* ((max(0,x) - max(0,-x)) - max(0,x-1) + max(0,-x-1))\n",
    "        normalize_linear1.weight.data = torch.Tensor([[1],[-1],[1],[-1]])\n",
    "        normalize_linear1.bias.data=torch.Tensor([0,0,-1,-1])\n",
    "        #print(normalize_linear1.weight)\n",
    "        #print(normalize_linear1.bias)\n",
    "        A = 100-1e-6\n",
    "        normalize_linear2 = torch.nn.Linear(3,1)\n",
    "        normalize_linear2.weight.data = torch.Tensor([[A,-A,-A,A]])\n",
    "        normalize_linear2.bias.data=torch.Tensor([0])\n",
    "        self.normalizer = torch.nn.Sequential(\n",
    "            normalize_linear1,\n",
    "            torch.nn.ReLU(),\n",
    "            normalize_linear2)\n",
    "\n",
    "    def forward(self, observation):\n",
    "        # NOTE: You may have to process (normalize) observation in the correct\n",
    "        #       way before using this. See `common.preprocessing.preprocess_obs`\n",
    "        action_hidden, value_hidden = self.extractor(observation)\n",
    "        action = self.action_net(action_hidden)\n",
    "        return self.normalizer(action) #, self.value_net(value_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: model = PPO(\"MlpPolicy\", \"Pendulum-v0\")\n",
    "model = PPO.load(\"ppo_acc_200000_steps-improve.zip\")\n",
    "model.policy.to(\"cpu\")\n",
    "onnxable_model = OnnxableActionPolicy(model.policy.mlp_extractor, model.policy.action_net, model.policy.value_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxable_model.normalizer(torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 2)\n",
    "torch.onnx.export(onnxable_model, dummy_input, \"ppo_acc_200000_steps-improve.onnx\", opset_version=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load and test with onnx\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"ppo_acc_200000_steps-improve.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"ppo_acc_200000_steps-improve.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "observation = np.zeros((1, 2)).astype(np.float32)\n",
    "ort_sess = ort.InferenceSession(\"ppo_acc_200000_steps-improve.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[100.00001]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(ort_sess.run(None, {'input.1': [[50,-99.0]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"acc-variant-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "[100.4 141. ]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs = [50,-99.0]\n",
    "env.unwrapped.state = obs\n",
    "for i in range(0,300):\n",
    "    action = ort_sess.run(None, {'input.1': [[obs[0],obs[1]]]})[0][0]\n",
    "    #action = np.clip(action,-100.,100.)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    if dones:\n",
    "        print(\"DONE\")\n",
    "        print(obs)\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename output nodes to not purely numeric names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('ppo_acc_200000_steps-improve.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model.graph.output[0].name = \"out1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model.graph.node[len(onnx_model.graph.node)-1].output[0]=\"out1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input.1'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.input[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model, 'ppo_acc_200000_steps-improve.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnequiv-tf1",
   "language": "python",
   "name": "nnequiv-tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
